{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_SVM_CV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnhmLsSGfPY6",
        "colab_type": "text"
      },
      "source": [
        "# import package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRrZh0ZlSWnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# from sklearn import cross_validation\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# train_test_split的作用是 把数据集分解成训练数据集，测试数据集\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "# K-fold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# SVM\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coA6pklZfY7c",
        "colab_type": "text"
      },
      "source": [
        "## Connect Google Drive.\n",
        "## This must be authorized by your Google account.\n",
        "## Please note the ***file path***！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efZOJ9euShTk",
        "colab_type": "code",
        "outputId": "5429f5e0-b9ff-4838-c636-bc40c9d5585b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive/Big Data\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test.csv',\n",
              " 'train.csv',\n",
              " 'five.png.csv',\n",
              " 'train-images-idx3-ubyte.gz',\n",
              " 'train-images.idx3-ubyte',\n",
              " 't10k-images-idx3-ubyte.gz',\n",
              " 'train-labels.idx1-ubyte',\n",
              " 't10k-labels-idx1-ubyte.gz',\n",
              " 'train-labels-idx1-ubyte.gz',\n",
              " 't10k-images.idx3-ubyte',\n",
              " 't10k-labels.idx1-ubyte']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPXgSUo9SZhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load MNIST training data\n",
        "# 运行MNIST训练数据\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Pre-process MNIST data and split it into train, test data sets\n",
        "# 预处理MNIST数据并将其分为 训练数据集，测试数据集\n",
        "features = train.columns[1:]\n",
        "X = train[features]\n",
        "y = train['label']\n",
        "\n",
        "# test_size=0.3是分解比例，分别是训练集70%和测试集30%, 如果是整数的话就是样本的数量\n",
        "# random_state=0 ，决策树由于前面数据集的分解是随机的,导致由于每次生成的树都是不一样的，所以用这个参数保证每次产生的树一致\n",
        "X_train, X_test, y_train, y_test = train_test_split(X/255, y, test_size=0.7, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4djyvEgq0_v",
        "colab_type": "text"
      },
      "source": [
        "# SVM\n",
        "## 10-Fold CV\n",
        "Tuning Hyperparameter ***C*** (Penalty factor：Tolerance for error)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GalMG9Q2SwDb",
        "colab_type": "code",
        "outputId": "e25ff01f-74cf-44cf-c389-557581f7535e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# K-fold\n",
        "Used to put the result value of each model\n",
        "cv_scores = []\n",
        "C_range = np.array([0.1, 0.5, 1, 5, 10, 50])\n",
        "best_score = 0\n",
        "best_C = 0\n",
        "for i,n in enumerate(C_range):\n",
        "  print('i=',i,'n=',n)\n",
        "  SVM = SVC(kernel='rbf',C=n,gamma = 0.05)\n",
        "  #cv：Choose the number of folds for each test, here I choose 10-fold \n",
        "  scores = cross_val_score(SVM,X_train,y_train,cv=10)   \n",
        "  cv_scores.append(scores.mean())\n",
        "  if (scores.mean() > best_score).all():\n",
        "    best_score = scores.mean()\n",
        "    best_C = n\n",
        "    print(\"best_score: %f\" %best_score)\n",
        "    print(\"best_C %d\" %best_C)\n",
        "    \n",
        "# Drawing\n",
        "plt.plot(C_range,cv_scores,label='kernel=linear')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Accuracy under different Penalty-Factor C')\n",
        "plt.xlabel('C_range')\n",
        "plt.ylabel('Accuracy')\t\t# Select the best parameters by image\n",
        "plt.annotate('Best C = ' + str(best_C) + ', Score = '+ str(round(best_score,4)), xy=(best_C, best_score), xytext=(-3,0.94), arrowprops=dict(facecolor='black', shrink=0.05))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i= 0 n= 0.1\n",
            "best_score: 0.902846\n",
            "best_C 0\n",
            "i= 1 n= 0.5\n",
            "best_score: 0.960000\n",
            "best_C 0\n",
            "i= 2 n= 1.0\n",
            "best_score: 0.967143\n",
            "best_C 1\n",
            "i= 3 n= 5.0\n",
            "best_score: 0.969286\n",
            "best_C 5\n",
            "i= 4 n= 10.0\n",
            "i= 5 n= 50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Krwf7p6tT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the Random Forest classifier. Fit the train data\n",
        "# 训练随机森林分类器。 拟合训练的数据\n",
        "clf_svm = SVC(kernel='linear',,C=best_C,gamma = 0.05)\n",
        "# 选择最优的K，进行重新训练模型\n",
        "best_Kfold = cross_val_score(clf_svm, X_train, y_train, cv=10, scoring='accuracy')\n",
        "clf_svm.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Predict the handwritten digits in the test data\n",
        "# 预测测试数据中的手写数字\n",
        "y_pred_svm = clf_svm.predict(X_test)\n",
        "\n",
        "\n",
        "# Measure accuracy of the prediction\n",
        "# Measure accuracy of the prediction\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"Random Forest accuracy（set kernel=linear）: %f\" % acc_svm)\n",
        "\n",
        "# Now use the whole train set to predict the test set\n",
        "clf_svm = RandomForestClassifier()\n",
        "clf_svm.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2IYrovqe4mF",
        "colab_type": "text"
      },
      "source": [
        "#Verify the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G1sIW_3NBW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict the test data in 'test.csv' file\n",
        "# TestFile=\"test.csv\"\n",
        "# 预测“test.csv”文件中的 测试数据\n",
        "# TestFile = “test.csv”\n",
        "# TestFile = \"five.png.csv\"\n",
        "TestFile = \"five.png.csv\"\n",
        "test = pd.read_csv(TestFile)\n",
        "y_pred_svm = clf_svm.predict(test)\n",
        "print(y_pred_svm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImxLxjMdNUhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(linewidth=200)\n",
        "with open(TestFile, 'r') as csv_file:\n",
        "    for didx, data in enumerate(csv.reader(csv_file)):\n",
        "        if \"pixel\" in data[0]: continue\n",
        "\n",
        "        # label = data[0]\n",
        "        label = y_pred_svm[didx - 1]\n",
        "\n",
        "        # The rest of columns are pixels\n",
        "        # 其余列为像素\n",
        "        pixels = data\n",
        "\n",
        "        # Make those columns into a array of 8-bits pixels\n",
        "        # This array will be of 1D with length 784\n",
        "        # The pixel intensity values are integers from 0 to 255\n",
        "        # 使这些列成为8位像素的数组\n",
        "        # 该数组为一维数组，长度为784\n",
        "        # 像素强度值是0到255之间的整数\n",
        "        pixels = np.array(pixels, dtype='uint8')\n",
        "\n",
        "        # Reshape the array into 28 x 28 array (2-dimensional array)\n",
        "        # 将阵列重塑为28 x 28阵列（二维阵列\n",
        "        pixels = pixels.reshape((28, 28))\n",
        "        print(pixels)\n",
        "\n",
        "        # Plot\n",
        "        plt.title('Predicted as {label}'.format(label=label))\n",
        "        plt.imshow(pixels, cmap='gray')\n",
        "        plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}